---
layout: splash
title: "Implementing Machine Learning Models for Heart Disease Prediction"
author: "Victor Murcia"
subtitle: "Classifiers for categorical data"
date: 2022-08-19 05:27:00 -0400
tags: jupyter_notebook  machine_learning classifier data_science grid_search optimization portfolio
background: '/img/posts/hpbg.jpg'
---


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<p>The accurate prediction and diagnosis of diseases is at the forefront of challenges that need to be addressed by medical professionals. 
This is a complicated task due to the myriad of factors that can contribute towards an ailment. In the United States, heart disease is the 
leading cause of death in the population with 696,962 deaths reported in 2021 (1 in every 5 deaths). <a href = "https://www.cdc.gov/nchs/fastats/heart-disease.htm">https://www.cdc.gov/nchs/fastats/heart-disease.htm</a>. 
As such, it is imperative to understand the causes and factors that lead to this deadly disease.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\intro pic.jpg" width = 600 height = 800></p>

<p>In this project I'll be showing how machine learning classifier models can be trained and used to predict heart disease. The dataset I'll be using here is the 
Heart Disease Dataset that I extracted from the UC Irvine Machine Learning Repository found here: <a href = "https://archive-beta.ics.uci.edu/ml/datasets/heart+disease">https://archive-beta.ics.uci.edu/ml/datasets/heart+disease</a>. 
This dataset contains databases from Cleveland, Hungary, Switzerland, and the VA Long Beach with each containing 76 different attributes of 
categorical and numerical types. This data was collected by the following institutions back in 1988:</p>

<ul>
    <li>University Hospital, Zurich, Switzerland</li>
    <li>University Hospital, Basel, Switzerland</li>
    <li>V.A. Medical Center, Long Beach and Cleveland Clinic Foundation</li>
</ul>

<h2>Exploring the Data</h2>
<p>This dataset has a healthy mixture of numerical and categorical variables. As such, it was necessary to make modifications in order to facilitate 
    their usage in the feature selection and modeling process. If you would like to see my process of preparing the data you can check out my post 
    <a href ="https://victormurcia.github.io/Predicting-Heart-Disease-with-ML-Classifiers/">here</a> or my repository <a href = "https://github.com/victormurcia/Heart-Disease-Prediction-with-Machine-Learning-Classifiers">here</a>. 
    For now I'll simply include the pandas_profiling report on the cleaned dataframe.</p>
<center><iframe src="\img\posts\Heart Disease\eda.html" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" width="75%" height="500"></iframe>
</center>

<p>The first thing to note is that these are a lot of variables to work with!  Though having more features to our model can make them more accurate,
    it also makes them less exaplainable (known as the curse of dimensionality). Machine learning models often suffer from this lack of explainability,
    and are treated as black-box models which can make it difficult to formulate and convey actionable insights from the model results. In other words, 
    having too many features in our model makes it less interpretable.</p>

<p>As such, I like to err in the direction of starting my models with less variables/dimensions if a good accuracy score can still be attained since 
    then I can more easily explain what my model is actually doing. The process of eliminating these unwanted and/or redunant features in our data 
    is known as dimensionality reduction.</p>

<h3>Feature Selection through Dimensionality Reduction Via Chi Squared Test</h3>

<p>There are many techniques that can be used to carry out dimensionality reduction that fall into the category of feature selction or feature extraction.
    feature selection. In this case, I'm interested excluding attributes that are present in the data. I'll do this through the Chi Squared Test which is 
    type of filter method.</p>

<p>The null hypothesis for the chi2 test is that two categorical variables are independent. Therefore, a higher value of the chi2 statistic means that 
    two categorical variables are dependent and are thus more useful for classification. In other words, the highest chi squared values will 
    represent the strongest relationships between our dependent variable (the diagnosis) and our independent variable and should therefore be the 
    ones that we should focus on during the model development (at least initially). </p>

<p>I applied the Chi Squared Test on the data and chose the best 10 features. The results of this process are shown in the table below.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\chi squared test.JPG" width = 600 height = 800></p>

<p>I will now generate a new dataframe that uses these variables now. These will be the 10 independent variables that I will use to predict 
    whether there is a positive or negative diagnosis of heart disease.</p>


<center><iframe src="\img\posts\Heart Disease\eda2.html" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" width="75%" height="500"></iframe>
</center>

<p>The pairplot below also helps us readily identify trends that I could analyze further between the numerical variables as well as give us an idea of 
    how certain variables are likely to contribute towards the prediction of heart disease from the model. The colors designate whether a patient will 
have heart disease (blue = yes, orange = no). </p>


<p style="text-align:center;"><img src="\img\posts\Heart Disease\pairplot.png" width = 500 height = 500></p>

<p>For instance we can see that age and max_heart_rate have an approximately negative linear relationship.</p>
<p>It can also be seen that the lower the max_heart_rate the more likely the patient will have a positive diagnosis of heart disease. There is evidence in the literature for this to be true, since max_heart_rate 
in this case corresponds to the heart rate achieved after exercise. </p>
<p>It can also be seen that a positive heart disease diagnosis is more frequent with increased age.</p>

<p>With this understanding of the variables and having reduced the dimensionality of the dataset such that the model will use the most 
    10 most important features based on the Chi Squared Test, I will now turn my attention to building and testing a set of classifier models.</p>

<h2>Building and Assessing the Performance of the Classifier Models</h2>
<p>I'll split my data using the 80/20 Pareto principle to start things off. Then, I'll test out the following classifiers with their default 
    parameters and see how well they perform. </p>

<ul>
    <li>Linear Perceptron</li>
    <li>Gaussian Naive Bayes</li>
    <li>Random Forest</li>
    <li>Extreme Gradient</li>
    <li>K-Neighbors</li>
    <li>Decision Tree</li>
    <li>Extreme Gradient Boosting</li>
    <li>Gaussian Process</li>
    <li>Support Vector</li>
    <li>MLP</li>
</ul>

<p>The results of the models are shown below:</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\model test initial.JPG" width = 500 height = 500></p>

<p>Very nice! The Random Forest Classifier and the Extreme Gradient Boost (XGBoost) Classifier performed really well straight from the box! They both 
    achieved accuracy scores of 0.9854 which is excellent. Their sensitivity and specificity are both 0.9714 and 1.0 respectively. Since their performance 
    is equal, I decided to go for XGBoost since it is generally a better performing and efficient algorithm than Random Forest.</p>

<h2>Optimizing and Cross Validating the XGBoost Classifier via Parameter Search Exploration</h2>

<p>The performance of the XGBoost classifier is already really good. However, it won't hurt to improve it even further through a parameter space 
    exploration. There's quite a few parameters at our disposal to tune for XGBoost which you can find in the <a href = "https://xgboost.readthedocs.io/en/stable/parameter.html">documentation</a>.</p>

<p>I decided to explore and optimize the following parameters and see if an even better performance can be achieved:</p>

<ul>
    <li>learning_rate</li>
    <li>max_depth</li>
    <li>n_estimators </li>
</ul>

<p>In addition, to exploring parameter space, I also applied a k-fold cross-validation with k=5. Cross-validation is an important aspect of model testing 
    and optimization since it can help in the detection of overfitting and selection bias problems. In other words, cross-validation is a good way to 
    assess how generalizable the model is.</p>

<p>I've included a neat visualization of the grid search exploration results below. The 3D scatter plot below shows the accuracy scores obtained 
    from the various combinations that I explored through the grid search. The color scale represents the accuracy score (purple is low and light green is high).
    The size of the spheres represents the standard deviation of the generated model (small sphere means low variance and big sphere means high variance).
    Therefore, the best model is the sphere with the lightest green color and the smallest size.</p>

<center><iframe src="\img\posts\Heart Disease\gridsearch1.html" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" width="750" height="750"></iframe>
</center>

<p>The results of the parameter exploration resulted in an accuracy score of 1.0 which is better than what I had before. In addition to the improvement 
    in the classification accuracy of the model, this model was also obtained by cross-validation which makes the model performance more reliable. The final parameters are: </p>

<ul>
    <li>learning_rate = 10</li>
    <li>max_depth = 11</li>
    <li>n_estimators = 130</li>
</ul>

<p>The confusion matrix for this model is shown below. The confusion matrix is a good way to track the number of false/true negatives/positives 
    classifications that the model is generating. From it we can see that there are 96 true positives, 109 true negatives, 0 false negatives, and 
0 false positives. This is great! The lack of false negatives is particularly thrilling since in this particular application, a false negative would 
result in the neglect of the condition which would be bad news for the patient.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\confusion mat.png" width = 500 height = 500></p>

<h3>ROC-AUC Curves of Model</h3>

<p>Let's now look at the Receiver operating characteristic curve (ROC curve) and the area under the curve (AUC) for this model. 
    ROC is a probability curve and AUC represents the degree or measure of separability. 
    The Higher the AUC, the better the model is at distinguishing between patients with heart disease and no heart disease. 
    An excellent model has AUC near to the 1 which means it has a good measure of separability. 
    A poor model has an AUC near 0 which means it has the worst measure of separability.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\roc_auc.png" width = 500 height = 500></p>

<p>The AUC for this model is 1.0 which means that the model has a high degree of separability which is desired.</p>

<h2>Understanding the Classifier Decisions</h2>

<p>The generated model is performing really well! However, does the decision making process that the model is using to make a diagnosis make sense?
    Let's try to get a better understanding of how our classifier model is making the decision 
    to diagnose heart disease. I'll be first using the ELI5 package to see the weights that the different features of our model have when 
    making a heart disease diagnosis.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\eli5.JPG" width = 500 height = 500></p>

<p>Interesting, the top 5 features that contribute towards the heart disease diagnosis decision are as follows:</p>

<ul>
    <li>cp_typical_angina</li>
    <li>num_major_vessels</li>
    <li>st_depression</li>
    <li>max_heart_rate</li>
    <li>cholesterol</li>
</ul>

<p>These all make sense at a glance. Let's look at them deeper to better understand their behavior firstly through Partial Depdence Plots</p>

<h3>Partial Dependence Plots - Feature Effects On Model Prediction</h3>

<p>In PDPs, a single variable is varied in a single row across a range of values in order to see what effect it has on the outcome. 
    It does this for several rows and plots the average effect. Below are the PDPs for the features with the largest weights towards a 
    diagnosis of heart disease. Therefore, if the PDP is positive then that feature contributes towards a <strong>positive</strong> heart disease 
    diagnosis, if it's negative it contributes towards a <strong>negative</strong> heart disease diagnosis.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\pdps.jpg" width = 1200 height = 1200></p>

<p>From the PDPs we can see the following:</p>
<ul>
    <li>Having a positive result for typical angina <strong>decreases</strong> the probability of heart disease</li>
    <li>As the number of major blood vessels increases, the probability of heart disease <strong>decreases</strong>.</li>
    <li>As the slope of the ST depression in the ECG goes from upsloping to downsloping, the probability of heart disease <strong>decreases</strong></li>
    <li>The probability of heart disease is <strong>non-linear</strong> based on heart-rate and cholesterol</li>
</ul>
    
<p>The dependence on having a typical angina makes sense. Angina is a type of chest pain caused by reduced blood flow to the heart. 
    There's different types of angina (stable , unstable, variant and refractory). 
    Typical angina is common and is generally experienced during periods of physical exertion and usually goes away before long. 
    The PDP for typical angina shows that when a patient exhibits this condition the likelihood of them having heart disease goes down which 
    makes sense.</p>

<p>The dependence on increased number of vessels seen in fluoroscopy also makes sense.
    If more vessels are seen during this measurement, then it is indicative of better blood flow and suggests a healthy heart. This is 
    indeed what is observed in the PDP plot for this feature.</p>

<p>The dependence seen for the ST-segment depression is tougher to interpret because there are other factors that are needed from the ECG
    to get a fuller picture of the situation. However, the PDP plot suggests that as the slope of the ST-segment goes from having a postive slope to
 a negative slope, the probability of heart disease decreases.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\ST-segment-depression.png" width = 600 height = 600></p>

<p>We can also look at 2D-PDP plots to get information about how the interaction between variables contributes to heart disease. The 2D PDP plots
    below will show the interactions between the typical angina feature and the next top 4 features in the mdoel. The color scale 
    in the plots below represents the probability of a heart disease diagnosis. Blue colors mean lower probability of heart disease while red 
    colors represent higher probability of heart disease.</p>

<p style="text-align:center;"><img src="\img\posts\Heart Disease\2dpdps.jpg" width = 600 height = 600></p>

<p>From the plots above we can see the following:</p>

<ol type="a">
    <li>Having no blood vessels show up in fluoroscopy AND not having a typical angina results in a high chance of heart disease</li>
    <li>Having a high heart rate AND not not having a typical angina results in a high chance of heart disease</li>
    <li>Having an upsloping ST-segment AND not having a typical angina results in a high chance of heart disease</li>
    <li>Having low cholesterol AND not having a typical angina results in a high chance of heart disease</li>
</ol>

<p>Hmmm, the first three interactions between the typical angina diagnosis with the fluoroscopy results, heart rate measurements and the 
    ST-segment make sense based on literature reports. However, low cholesterol having a higher probability of heart disease doesn't seem to be in agreement with the 
    medical consensus of high cholesterol levels being a high-risk factor of heart problems. Why could this be?</p>

<p>This strange behavior could be explained by the fact that the cholesterol levels reported in this work appears to be the TOTAL serum cholesterol levels. Cholesterol actually travels in two
     different types of lipoproteins known as low-density lipoproteins (LDLs) and high-density lipoproteins (HDLs). High LDL levels are associated 
     with increased risk of heart disease. High HDL levels on the other hand are associated with lowered risk of heart disease. The data from 
     this project doesn't separate between those two types of cholesterols which would explain the strange behavior of cholesterol seen here.</p>

<h3>SHAP Values for Assessment of Contributions of Model Features</h3>

<p>Let's look at the Shapley Additive Explanations (SHAP). 
    SHAP is a method from game theory that can help explain the outputs from a machine learning model. 
    More specifically, these SHAP values allow us to understand the impact from each feature in our model by breaking down the predictions made by the model. 
    It's important to note that SHAP values are not a model assessment criteria. 
    In other words they don't evaluate the quality of the model. 
    They are here to help us understand the importance/contribution of each feature in our model.</p>

<center><iframe src="\img\posts\Heart Disease\shap1.html" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" width="850" height="450"></iframe>
</center>
<h2>Final Predictions</h2>

<h2>Conclusions</h2>
